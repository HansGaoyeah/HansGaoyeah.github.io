<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="高航，个人学习笔记" />





  <link rel="alternate" href="/atom.xml" title="高航的博客" type="application/atom+xml" />






<meta name="description" content="开心就好">
<meta property="og:type" content="website">
<meta property="og:title" content="高航的博客">
<meta property="og:url" content="http://gaohangcs.com/index.html">
<meta property="og:site_name" content="高航的博客">
<meta property="og:description" content="开心就好">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="高航的博客">
<meta name="twitter:description" content="开心就好">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://gaohangcs.com/"/>





  <title>高航的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">高航的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">日积月累</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/home" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/user" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/th" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archive" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://gaohangcs.com/2018/11/04/学习刘建平博客之线性回归实例/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高航">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高航的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/04/学习刘建平博客之线性回归实例/" itemprop="url">学习刘建平博客之线性回归实例</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-04T21:41:39+08:00">
                2018-11-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="用scikit-learn和pandas学习线性回归"><a href="#用scikit-learn和pandas学习线性回归" class="headerlink" title="用scikit-learn和pandas学习线性回归"></a>用scikit-learn和pandas学习线性回归</h2><p>这段时间准备将几个传统的机器学习模型给重新复习一遍，今晚便是针对回归分析的复习，主要去做了刘建平老师的博客的一个实例，熟悉scikit-learn和pandas，下面进入正题。</p>
<h3 id="1-获取数据，定义问题"><a href="#1-获取数据，定义问题" class="headerlink" title="1.获取数据，定义问题"></a>1.获取数据，定义问题</h3><p>数据的介绍在这： <a href="http://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant</a></p>
<p>数据的下载地址在这： <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/00294/" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/machine-learning-databases/00294/</a></p>
<p>里面是一个循环发电场的数据，共有9568个样本数据，每个数据有5列，分别是:AT（温度）, V（压力）, AP（湿度）, RH（压强）, PE（输出电力)。我们不用纠结于每项具体的意思。</p>
<p>我们的问题是得到一个线性的关系，对应PE是样本输出，而AT/V/AP/RH这4个是样本特征， 机器学习的目的就是得到一个线性回归模型，即:</p>
<p>PE=θ0+θ1∗AT+θ2∗V+θ3∗AP+θ4∗RHPE=θ0+θ1∗AT+θ2∗V+θ3∗AP+θ4∗RH
　　　　</p>
<p>而需要学习的，就是θ0,θ1,θ2,θ3,θ4θ0,θ1,θ2,θ3,θ4这5个参数。</p>
<h3 id="2-整理数据"><a href="#2-整理数据" class="headerlink" title="2.整理数据"></a>2.整理数据</h3><p>下载后的数据可以发现是一个压缩文件，解压后可以看到里面有一个xlsx文件，我们先用excel把它打开，接着“另存为“”csv格式，保存下来，后面我们就用这个csv来运行线性回归。</p>
<p>打开这个csv可以发现数据已经整理好，没有非法数据，因此不需要做预处理。但是这些数据并没有归一化，也就是转化为均值0，方差1的格式。也不用我们搞，后面scikit-learn在线性回归时会先帮我们把归一化搞定。</p>
<h3 id="3-用pandas来读取数据"><a href="#3-用pandas来读取数据" class="headerlink" title="3.用pandas来读取数据"></a>3.用pandas来读取数据</h3><p>先把要导入的库声明了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">#%matplotlib inline	#ipython里的库，在pycharm里没用</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn import datasets, linear_model</span><br></pre></td></tr></table></figure>
<p>接着我们就可以用pandas读取数据了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#read_csv里面的参数是csv在你电脑上的路径，此处csv文件放在目录下面的data目录里</span><br><span class="line">data = pd.read_csv(&apos;./data/ccpp.csv&apos;)</span><br></pre></td></tr></table></figure></p>
<p>接着读取数据，结果如图所示<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#读取前五行数据，如果是最后五行，用data.tail()</span><br><span class="line">print(data.head())</span><br></pre></td></tr></table></figure></p>
<p><img src="../../img/线性回归1.png" alt=""></p>
<h3 id="4-准备运行算法的数据"><a href="#4-准备运行算法的数据" class="headerlink" title="4.准备运行算法的数据"></a>4.准备运行算法的数据</h3><p>我们看看数据的维度<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.shape</span><br></pre></td></tr></table></figure></p>
<p>结果是(9568, 5)。说明我们有9568个样本，每个样本有5列。</p>
<p>现在我们开始准备样本特征X，我们用AT， V，AP和RH这4个列作为样本特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data.shape</span><br><span class="line">X = data[[&apos;AT&apos;, &apos;V&apos;, &apos;AP&apos;, &apos;RH&apos;]]</span><br><span class="line">print(X.head()) #  可以看到X的前五条输出</span><br><span class="line">#接着我们准备样本输出y， 我们用PE作为样本输出</span><br><span class="line">y = data[[&apos;PE&apos;]]</span><br><span class="line">print(y.head()) #  可以看到y的前五条输出</span><br></pre></td></tr></table></figure></p>
<p><img src="../../img/线性回归2.png" alt=""></p>
<h3 id="5-划分训练集和测试集"><a href="#5-划分训练集和测试集" class="headerlink" title="5.划分训练集和测试集"></a>5.划分训练集和测试集</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import  train_test_split   #划分训练集和测试集</span><br><span class="line">#  我们把X和y的样本组合划分成两部分，一部分是训练集，一部分是测试集</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)</span><br><span class="line">#  查看下训练集和测试集的维度</span><br><span class="line">#  可以看到75%的样本数据被作为训练集，25%的样本被作为测试集</span><br><span class="line">print(X_train.shape)</span><br><span class="line">print(y_train.shape)</span><br><span class="line">print(X_test.shape)</span><br><span class="line">print(y_test.shape)</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p>(7176, 4)</p>
<p>(7176, 1)</p>
<p>(2392, 4)</p>
<p>(2392, 1)　　　　</p>
<p>可以看到75%的样本数据被作为训练集，25%的样本被作为测试集。</p>
<h3 id="6-运行scikit-learn的线性模型"><a href="#6-运行scikit-learn的线性模型" class="headerlink" title="6.运行scikit-learn的线性模型"></a>6.运行scikit-learn的线性模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#  scikit-learn的线性回归算法使用的是最小二乘法来实现的</span><br><span class="line">linreg = LinearRegression()</span><br><span class="line">linreg.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">#  拟合完毕后，我们看看我们的需要的模型系数结果</span><br><span class="line">#  这样我们就得到了在步骤1里面需要求得的5个值。也就是说PE和其他4个变量的关系如下：</span><br><span class="line">#  PE=447.06297099−1.97376045∗AT−0.23229086∗V+0.0693515∗AP−0.15806957∗RH</span><br><span class="line">print(linreg.intercept_)</span><br><span class="line">print(linreg.coef_)</span><br></pre></td></tr></table></figure>
<p><img src="../../img/线性回归5.png" alt=""></p>
<h3 id="7-模型评价"><a href="#7-模型评价" class="headerlink" title="7.模型评价"></a>7.模型评价</h3><p>我们需要评估我们的模型的好坏程度，对于线性回归来说，我们一般用均方差或者均方根差在测试集上的表现来评价模型的好坏<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#  看看我们的模型的MSE和RMSE</span><br><span class="line">#  模型拟合测试集</span><br><span class="line">y_pred = linreg.predict(X_test)</span><br><span class="line"># 用scikit-learn计算MSE</span><br><span class="line">print(&quot;MSE:&quot;,metrics.mean_squared_error(y_test, y_pred))    #  MSE是均方误差</span><br><span class="line"># 用scikit-learn计算RMSE</span><br><span class="line">print(&quot;RMSE:&quot;,np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  #  RMSE是均方根误差</span><br></pre></td></tr></table></figure></p>
<p><img src="../../img/线性回归3.png" alt=""></p>
<p>输出如下：</p>
<p>MSE: 20.0804012021</p>
<p>RMSE: 4.48111606657</p>
<p>得到了MSE或者RMSE，如果我们用其他方法得到了不同的系数，需要选择模型时，就用MSE小的时候对应的参数。</p>
<p>比如这次我们用AT， V，AP这3个列作为样本特征。不要RH， 输出仍然是PE。代码如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">X = data[[&apos;AT&apos;, &apos;V&apos;, &apos;AP&apos;]]</span><br><span class="line">y = data[[&apos;PE&apos;]]</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)</span><br><span class="line">linreg = LinearRegression()</span><br><span class="line">linreg.fit(X_train, y_train)</span><br><span class="line">#模型拟合测试集</span><br><span class="line">y_pred = linreg.predict(X_test)</span><br><span class="line">from sklearn import metrics</span><br><span class="line"># 用scikit-learn计算MSE</span><br><span class="line">print(&quot;MSE:&quot;,metrics.mean_squared_error(y_test, y_pred))</span><br><span class="line"># 用scikit-learn计算RMSE</span><br><span class="line">print(&quot;RMSE:&quot;,np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<p>MSE: 23.2089074701</p>
<p>RMSE: 4.81756239919</p>
<p>可以看出，去掉RH后，模型拟合的没有加上RH的好，MSE变大了。</p>
<h3 id="8-交叉验证"><a href="#8-交叉验证" class="headerlink" title="8.交叉验证"></a>8.交叉验证</h3><p>我们可以通过交叉验证来持续优化模型，代码如下，我们采用10折交叉验证，即cross_val_predict中的cv参数为10：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = data[[&apos;AT&apos;, &apos;V&apos;, &apos;AP&apos;, &apos;RH&apos;]]</span><br><span class="line">y = data[[&apos;PE&apos;]]</span><br><span class="line">from sklearn.model_selection import cross_val_predict</span><br><span class="line">predicted = cross_val_predict(linreg, X, y, cv=10)</span><br><span class="line"># 用scikit-learn计算MSE</span><br><span class="line">print(&quot;MSE:&quot;,metrics.mean_squared_error(y, predicted))</span><br><span class="line"># 用scikit-learn计算RMSE</span><br><span class="line">print(&quot;RMSE:&quot;,np.sqrt(metrics.mean_squared_error(y, predicted)))</span><br></pre></td></tr></table></figure></p>
<p><img src="../../img/线性回归4.png" alt=""></p>
<p>可以看出，采用交叉验证模型的MSE比第一次的大，主要原因是我们这里是对所有折的样本做测试集对应的预测值的MSE，而第一次仅仅对25%的测试集做了MSE。两者的先决条件并不同。</p>
<h3 id="9-画图观察结果"><a href="#9-画图观察结果" class="headerlink" title="9.画图观察结果"></a>9.画图观察结果</h3><p>这里画图真实值和预测值的变化关系，离中间的直线y=x直接越近的点代表预测损失越低。代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(y, predicted)</span><br><span class="line">ax.plot([y.min(), y.max()], [y.min(), y.max()], &apos;k--&apos;, lw=4)</span><br><span class="line">ax.set_xlabel(&apos;Measured&apos;)</span><br><span class="line">ax.set_ylabel(&apos;Predicted&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="../../img/线性回归6.png" alt=""></p>
<h3 id="10-完整代码"><a href="#10-完整代码" class="headerlink" title="10.完整代码"></a>10.完整代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">#-*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">#%matplotlib inline     #  ipython专属</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn import datasets, linear_model</span><br><span class="line">from sklearn.model_selection import  train_test_split   #划分训练集和测试集</span><br><span class="line">from sklearn.linear_model import LinearRegression   #  运行scikit-learn的线性模型</span><br><span class="line">from sklearn import metrics</span><br><span class="line"># read_csv里面的参数是csv在你电脑上的路径，此处csv文件放在目录下面的data目录里</span><br><span class="line">data = pd.read_csv(&apos;./data/ccpp.csv&apos;)</span><br><span class="line"></span><br><span class="line">#读取前五行数据，如果是最后五行，用data.tail()</span><br><span class="line">print(data.head())</span><br><span class="line">#准备样本特征X，我们用AT， V，AP和RH这4个列作为样本特征。</span><br><span class="line">data.shape</span><br><span class="line">X = data[[&apos;AT&apos;, &apos;V&apos;, &apos;AP&apos;, &apos;RH&apos;]]</span><br><span class="line">print(X.head()) #  可以看到X的前五条输出</span><br><span class="line">#接着我们准备样本输出y， 我们用PE作为样本输出</span><br><span class="line">y = data[[&apos;PE&apos;]]</span><br><span class="line">print(y.head()) #  可以看到y的前五条输出</span><br><span class="line">#  我们把X和y的样本组合划分成两部分，一部分是训练集，一部分是测试集</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)</span><br><span class="line"></span><br><span class="line">#  查看下训练集和测试集的维度</span><br><span class="line">#  可以看到75%的样本数据被作为训练集，25%的样本被作为测试集</span><br><span class="line">print(X_train.shape)</span><br><span class="line">print(y_train.shape)</span><br><span class="line">print(X_test.shape)</span><br><span class="line">print(y_test.shape)</span><br><span class="line"></span><br><span class="line">#  scikit-learn的线性回归算法使用的是最小二乘法来实现的</span><br><span class="line">linreg = LinearRegression()</span><br><span class="line">linreg.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">#  拟合完毕后，我们看看我们的需要的模型系数结果</span><br><span class="line">#  这样我们就得到了在步骤1里面需要求得的5个值。也就是说PE和其他4个变量的关系如下：</span><br><span class="line">#  PE=447.06297099−1.97376045∗AT−0.23229086∗V+0.0693515∗AP−0.15806957∗RH</span><br><span class="line">print(linreg.intercept_)</span><br><span class="line">print(linreg.coef_)</span><br><span class="line"></span><br><span class="line">#  模型评价</span><br><span class="line">#  我们需要评估我们的模型的好坏程度，对于线性回归来说，我们一般用均方差或者均方根差在测试集上的表现来评价模型的好坏</span><br><span class="line">#  看看我们的模型的MSE和RMSE</span><br><span class="line">#  模型拟合测试集</span><br><span class="line">y_pred = linreg.predict(X_test)</span><br><span class="line"># 用scikit-learn计算MSE</span><br><span class="line">print(&quot;MSE:&quot;,metrics.mean_squared_error(y_test, y_pred))    #  MSE是均方误差</span><br><span class="line"># 用scikit-learn计算RMSE</span><br><span class="line">print(&quot;RMSE:&quot;,np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  #  RMSE是均方根误差</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">#  得到了MSE或者RMSE，如果我们用其他方法得到了不同的系数，需要选择模型时，就用MSE小的时候对应的参数。</span><br><span class="line">#  比如这次我们用AT， V，AP这3个列作为样本特征。不要RH， 输出仍然是PE。</span><br><span class="line">X = data[[&apos;AT&apos;, &apos;V&apos;, &apos;AP&apos;]]</span><br><span class="line">y = data[[&apos;PE&apos;]]</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)</span><br><span class="line">linreg = LinearRegression()</span><br><span class="line">linreg.fit(X_train, y_train)</span><br><span class="line">#模型拟合测试集</span><br><span class="line">y_pred = linreg.predict(X_test)</span><br><span class="line">from sklearn import metrics</span><br><span class="line"># 用scikit-learn计算MSE</span><br><span class="line">print(&quot;MSE:&quot;,metrics.mean_squared_error(y_test, y_pred))</span><br><span class="line"># 用scikit-learn计算RMSE</span><br><span class="line">print(&quot;RMSE:&quot;,np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span><br><span class="line">#  可以看出，去掉RH后，模型拟合的没有加上RH的好，MSE变大了。</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line">#  交叉验证</span><br><span class="line">#  我们可以通过交叉验证来持续优化模型，代码如下，我们采用10折交叉验证，即cross_val_predict中的cv参数为10：</span><br><span class="line">X = data[[&apos;AT&apos;, &apos;V&apos;, &apos;AP&apos;, &apos;RH&apos;]]</span><br><span class="line">y = data[[&apos;PE&apos;]]</span><br><span class="line">from sklearn.model_selection import cross_val_predict</span><br><span class="line">predicted = cross_val_predict(linreg, X, y, cv=10)</span><br><span class="line"># 用scikit-learn计算MSE</span><br><span class="line">print(&quot;MSE:&quot;,metrics.mean_squared_error(y, predicted))</span><br><span class="line"># 用scikit-learn计算RMSE</span><br><span class="line">print(&quot;RMSE:&quot;,np.sqrt(metrics.mean_squared_error(y, predicted)))</span><br><span class="line">#可以看出，采用交叉验证模型的MSE比第一次的大，主要原因是我们这里是对所有折的样本做测试集对应的预测值的MSE，而第一次仅仅对25%的测试集做了MSE。两者的先决条件并不同。</span><br><span class="line"></span><br><span class="line">#  这里画图真实值和预测值的变化关系，离中间的直线y=x直接越近的点代表预测损失越低。</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(y, predicted)</span><br><span class="line">ax.plot([y.min(), y.max()], [y.min(), y.max()], &apos;k--&apos;, lw=4)</span><br><span class="line">ax.set_xlabel(&apos;Measured&apos;)</span><br><span class="line">ax.set_ylabel(&apos;Predicted&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://gaohangcs.com/2018/11/03/交叉验证/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高航">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高航的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/03/交叉验证/" itemprop="url">交叉验证</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-03T16:05:45+08:00">
                2018-11-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>交叉验证是在机器学习建立模型和验证模型参数时常用的办法。交叉验证，顾名思义，就是重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”。　</p>
<ol>
<li><p>简单交叉验证：<br>首先，我们随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。、</p>
</li>
<li><p>S折交叉验证<br>S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数。</p>
</li>
<li><p>留一交叉验证<br>它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，我一般采用留一交叉验证。</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://gaohangcs.com/2018/11/03/从log文件中取出IP地址/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高航">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高航的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/03/从log文件中取出IP地址/" itemprop="url">从log文件中取出IP地址</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-03T13:50:24+08:00">
                2018-11-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>&emsp;&emsp;这一周多的时间做的工作十分枯燥，就是将反爬虫系统爬取下来的38000多个数据（IP地址信息）进行划分，将它们人工标注成爬虫和人类行为。</p>
<p>&emsp;&emsp;在全部标注完成后需要与原数据集中进行对比。对比后发现总数703个IP地址，但我只标注了695个，比总数少了8个，于是就有了这篇博文的内容。</p>
<h3 id="原始数据集"><a href="#原始数据集" class="headerlink" title="原始数据集"></a>原始数据集</h3><p><img src="../../img/9_18.png" alt=""></p>
<p>&emsp;&emsp;如上图所示，一行数据有很多信息，我只想要提取出第一个开头的IP地址，这里就要用到文件读取、正则表达式等知识。</p>
<p>###正则表达式</p>
<table>
<thead>
<tr>
<th style="text-align:left">字符</th>
<th style="text-align:right">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">\</td>
<td style="text-align:right">将下一个字符标记为一个特殊字符、或一个原义字符、或一个向后引用、或一个八进制转义符。例如，“n”匹配字符“n”。“\n”匹配一个换行符。串行“\”匹配“\”而“(”则匹配“(”。</td>
</tr>
<tr>
<td style="text-align:left">(?</td>
<td style="text-align:right">反向否定预查，与正向否定预查类拟，只是方向相反。例如“(?”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。</td>
</tr>
<tr>
<td style="text-align:left">\d</td>
<td style="text-align:right">匹配一个数字字符。等价于[0-9]。</td>
</tr>
<tr>
<td style="text-align:left">.</td>
<td style="text-align:right">匹配除“\n”之外的任何单个字符。</td>
</tr>
<tr>
<td style="text-align:left">{n}</td>
<td style="text-align:right">n是一个非负整数。匹配确定的n次。例如，“o{2}”不能匹配“Bob”中的“o”，但是能匹配“food”中的两个o。</td>
</tr>
<tr>
<td style="text-align:left">{n,m}</td>
<td style="text-align:right">m和n均为非负整数，其中n&lt;=m。最少匹配n次且最多匹配m次。例如，“o{1,3}”将匹配“fooooood”中的前三个o。“o{0,1}”等价于“o?”。请注意在逗号和两个数之间不能有空格。</td>
</tr>
<tr>
<td style="text-align:left">re.S</td>
<td style="text-align:right">使 . 匹配包括换行在内的所有字符</td>
</tr>
</tbody>
</table>
<h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># encoding: utf-8</span><br><span class="line">import sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">import pandas as pd</span><br><span class="line">import re</span><br><span class="line">import time</span><br><span class="line">import requests</span><br><span class="line">time1=time.time()</span><br><span class="line">######函数功能:能够提取ip地址，并且去重################</span><br><span class="line">def read_file(input_file_name,output_file_name):</span><br><span class="line">  _fLog = open(input_file_name)</span><br><span class="line">  sep = &apos;\n&apos;</span><br><span class="line">  ip_list=[]</span><br><span class="line">  for each in _fLog:</span><br><span class="line">    ip=re.findall(r&apos;(?&lt;![\.\d])(?:\d&#123;1,3&#125;\.)&#123;3&#125;\d&#123;1,3&#125;(?![\.\d])&apos;,str(each),re.S)</span><br><span class="line">    ip_list.append(ip[0])</span><br><span class="line">  # 列表去重:通过set方法进行处理</span><br><span class="line">  ids = list(set(ip_list))</span><br><span class="line">  print &quot;共解析ip个数:%s &quot;% len(ids)</span><br><span class="line">  ##写出数据到本地</span><br><span class="line">  # 设置输出文件路径</span><br><span class="line">  out = open(output_file_name, &quot;a&quot;)</span><br><span class="line">  # out.write(&quot;ip&quot; + sep)</span><br><span class="line">  for each in ids:</span><br><span class="line">    print each</span><br><span class="line">    out.write(each + sep)</span><br><span class="line">  ##关闭连接</span><br><span class="line">  out.close()</span><br><span class="line">  _fLog.close()</span><br><span class="line">  print &quot;ip提取完毕~~&quot;</span><br><span class="line">####主函数################</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">  input_file_name = &quot;D:/acs.log&quot;</span><br><span class="line">  output_file_name = &quot;D:/acs.txt&quot;</span><br><span class="line">  read_file(input_file_name, output_file_name)</span><br><span class="line">  time2 = time.time()</span><br><span class="line">  print u&apos;总共耗时：&apos; + str(time2 - time1) + &apos;s&apos;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://gaohangcs.com/2018/11/03/UIC会议心得/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高航">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高航的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/03/UIC会议心得/" itemprop="url">UIC会议心得</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-03T10:48:24+08:00">
                2018-11-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="UIC会议心得"><a href="#UIC会议心得" class="headerlink" title="UIC会议心得"></a>UIC会议心得</h1><p>&emsp;&emsp;有段时间没更博了，这段时间出了趟差，去广州参加IEEE Smart World大会中的UIC会议的答辩。所以这篇博客就讲下一个人出差答辩的经历。</p>
<p><img src="../../img/10.15_1.jpg" alt=""></p>
<p>&emsp;&emsp;国庆节1号凌晨0点11分导师给我发QQ问我能否用英文参加答辩，了解我的人都知道我英语真的很差，英语中我的口语最差，但我还是答应了，实在不想放弃这个机会。于是当天还在老家吃酒的我便立马去打印出来了论文，论文我暑假就读过完整版，再次上手虽然问题不大，但要演讲就又是一回事了。那一整天在忙论文的分段整理和买来回车票、订酒店这类事。由于是一个人出差，以前从来没有过，我相当重视这件事。</p>
<p><img src="../../img/10.15_2.jpg" alt=""></p>
<p>&emsp;&emsp;琐事处理完后便要认真准备答辩事宜了，我改签了返程火车票，3号上午便回到了学校。对着国庆前自己做的PPT练习，但操着一口不熟练的英语读这篇论文要花掉我30分钟去，这在这样的会议上是不被允许的。我所在的这场会议时长两小时，共六篇论文，平均一篇20分钟。接下来的事便是删演讲稿，原本之前做PPT时还在抱怨为什么导师为什么要删除启发式规则这节的内容，搞得论文都不对称了，结果到自己删演讲稿时懵逼了，感觉都是重点，哪里都删不了，在寝室删了一天也才只是从2300字删到1900多字。上楼找贺巩山大佬也只删到1700多字，模拟演讲时计时还要19分钟，很是头痛。最后是女朋友提醒，按照PPT去讲，而不是按照演讲稿去动PPT。这下一下就通了，一下就删掉了之前不舍得删的所谓的重点，最后删到了1400字。</p>
<p><img src="../../img/10.15_3.jpg" alt=""></p>
<p>&emsp;&emsp;由于英语口语太差，时间紧迫，一些不会发的音没时间去查阅词典，就很感谢各位大佬给我一句话一句话的语音发给我，跟着大佬的语音练习就很快的能够熟练朗读了。女朋友帮我写了开场白和结束语，还有每部分的串词。最后想了两个万能答案并且疯狂练习了两三天就准备出发了。</p>
<p><img src="../../img/10.15_4.jpg" alt=""></p>
<p>&emsp;&emsp;广州我有15年没去过了，也很是期待，会场在广东大厦，中山纪念堂旁边，在酒店安顿下来后便去到会场给老师拿投稿的发票，也熟悉下会场。晚上去点都德吃了个晚饭，第二天一上午还是继续练习。下午提前去到了会场，与左右的学长们聊了起来，学长都是博士，分别来自东北大学和西安电子科技大学，人都蛮好的。一点半会议正式开始，人很少，就只有答辩的几个，我是第二个上场答辩的，一切都很是顺利，老师唯独没有问我问题，不到20分钟便结束了我的答辩。会议结束后在场下与主持和学长学姐们边喝下午茶边聊天，学习到了不少。其余会场大都是外国人，各类大型会议，我参加的只是其中一个很小的会议，那种大型会议是会怼人的，提的问题都很尖锐。</p>
<p><img src="../../img/10.15_5.jpg" alt=""></p>
<p>&emsp;&emsp;离开会场便立刻前往腾讯微信总部，我向往的一个地方。晚上在广州塔转了转便差不多准备返程了。第一次一个人出差，很是平淡，没了大二大三时跟着老师去北京打蓝桥杯决赛时的激动。只想完成好导师交给我的任务，一个人玩也是很没意思的一件事，可能出差本身就是这样吧！</p>
<p><img src="../../img/10.15_6.jpg" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://gaohangcs.com/2018/10/24/主成分分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高航">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高航的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/24/主成分分析/" itemprop="url">主成分分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-24T19:20:00+08:00">
                2018-10-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据挖掘/" itemprop="url" rel="index">
                    <span itemprop="name">数据挖掘</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><p>&emsp;&emsp;用较少的变量去解释原始数据中的大部分变量，即将许多相关性很高的变量转化成彼此相互独立或不相关的变量。</p>
<p>&emsp;&emsp;在python中，主成分分析的函数位于scikit-learn下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.PCA(n_components = None, copy = True, whiten = False)</span><br></pre></td></tr></table></figure>
<h2 id="PCA算法流程"><a href="#PCA算法流程" class="headerlink" title="PCA算法流程"></a>PCA算法流程</h2><p>&emsp;&emsp;求样本x(i)x(i)的n’维的主成分其实就是求样本集的协方差矩阵XXTXXT的前n’个特征值对应特征向量矩阵W，然后对于每个样本x(i)x(i),做如下变换z(i)=WTx(i)z(i)=WTx(i)，即达到降维的PCA目的。</p>
<p>输入：n维样本集D=(x(1),x(2),…,x(m))D=(x(1),x(2),…,x(m))，要降维到的维数n’.</p>
<p>输出：降维后的样本集D′D′</p>
<p>　　　　1) 对所有的样本进行中心化： x(i)=x(i)−1m∑j=1mx(j)x(i)=x(i)−1m∑j=1mx(j)</p>
<p>　　　　2) 计算样本的协方差矩阵XXTXXT</p>
<p>　　　　3) 对矩阵XXTXXT进行特征值分解</p>
<p>　　　　4）取出最大的n’个特征值对应的特征向量(w1,w2,…,wn′)(w1,w2,…,wn′), 将所有的特征向量标准化后，组成特征向量矩阵W。</p>
<p>　　　　5）对样本集中的每一个样本x(i)x(i),转化为新的样本z(i)=WTx(i)z(i)=WTx(i)</p>
<p>　　　　6) 得到输出样本集D′=(z(1),z(2),…,z(m))D′=(z(1),z(2),…,z(m))</p>
<p>&emsp;&emsp;有时候，我们不指定降维后的n’的值，而是换种方式，指定一个降维到的主成分比重阈值t。这个阈值t在（0,1]之间。</p>
<h2 id="PCA算法总结"><a href="#PCA算法总结" class="headerlink" title="PCA算法总结"></a>PCA算法总结</h2><p>&emsp;&emsp;这里对PCA算法做一个总结。作为一个非监督学习的降维方法，它只需要特征值分解，就可以对数据进行压缩，去噪。因此在实际场景应用很广泛。为了克服PCA的一些缺点，出现了很多PCA的变种，比如第六节的为解决非线性降维的KPCA，还有解决内存限制的增量PCA方法Incremental PCA，以及解决稀疏数据降维的PCA方法Sparse PCA等。</p>
<p>　　　　PCA算法的主要优点有：</p>
<p>　　　　1）仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　</p>
<p>　　　　2）各主成分之间正交，可消除原始数据成分间的相互影响的因素。</p>
<p>　　　　3）计算方法简单，主要运算是特征值分解，易于实现。</p>
<p>　　　　PCA算法的主要缺点有：</p>
<p>　　　　1）主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。</p>
<p>　　　　2）方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</p>
<h2 id="sklearn-decomposition-PCA参数介绍"><a href="#sklearn-decomposition-PCA参数介绍" class="headerlink" title="sklearn.decomposition.PCA参数介绍"></a>sklearn.decomposition.PCA参数介绍</h2><p>PCA类基本不需要调参，一般来说，我们只需要指定我们需要降维到的维度，或者我们希望降维后的主成分的方差和占原始维度所有特征方差和的比例阈值就可以了。</p>
<p>1）n_components：这个参数可以帮我们指定希望PCA降维后的特征维度数目。最常用的做法是直接指定降维到的维度数目，此时n_components是一个大于等于1的整数。当然，我们也可以指定主成分的方差和所占的最小比例阈值，让PCA类自己去根据样本特征方差来决定降维到的维度数，此时n_components是一个（0，1]之间的数。当然，我们还可以将参数设置为”mle”, 此时PCA类会用MLE算法根据特征的方差分布情况自己去选择一定数量的主成分特征来降维。我们也可以用默认值，即不输入n_components，此时n_components=min(样本数，特征数)。</p>
<p>2）whiten ：判断是否进行白化。所谓白化，就是对降维后的数据的每个特征进行归一化，让方差都为1.对于PCA降维本身来说，一般不需要白化。如果你PCA降维后有后续的数据处理动作，可以考虑白化。默认值是False，即不进行白化。</p>
<p>3）svd_solver：即指定奇异值分解SVD的方法，由于特征分解是奇异值分解SVD的一个特例，一般的PCA库都是基于SVD实现的。有4个可以选择的值：{‘auto’, ‘full’, ‘arpack’, ‘randomized’}。randomized一般适用于数据量大，数据维度多同时主成分数目比例又较低的PCA降维，它使用了一些加快SVD的随机算法。 full则是传统意义上的SVD，使用了scipy库对应的实现。arpack和randomized的适用场景类似，区别是randomized使用的是scikit-learn自己的SVD实现，而arpack直接使用了scipy库的sparse SVD实现。默认是auto，即PCA类会自己去在前面讲到的三种算法里面去权衡，选择一个合适的SVD算法来降维。一般来说，使用默认值就够了。</p>
<p>除了这些输入参数外，有两个PCA类的成员值得关注。第一个是explained_variance_，它代表降维后的各主成分的方差值。方差值越大，则说明越是重要的主成分。第二个是explained_variance_ratio_，它代表降维后的各主成分的方差值占总方差值的比例，这个比例越大，则越是重要的主成分。</p>
<h2 id="PCA实例"><a href="#PCA实例" class="headerlink" title="PCA实例"></a>PCA实例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">%matplotlib inline</span><br><span class="line">from sklearn.datasets.samples_generator import make_blobs</span><br><span class="line"># X为样本特征，Y为样本簇类别， 共1000个样本，每个样本3个特征，共4个簇</span><br><span class="line">X, y = make_blobs(n_samples=10000, n_features=3, centers=[[3,3, 3], [0,0,0], [1,1,1], [2,2,2]], cluster_std=[0.2, 0.1, 0.2, 0.2], </span><br><span class="line">                  random_state =9)</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig, rect=[0, 0, 1, 1], elev=30, azim=20)</span><br><span class="line">plt.scatter(X[:, 0], X[:, 1], X[:, 2],marker=&apos;o&apos;)</span><br></pre></td></tr></table></figure>
<p>我们先不降维，只对数据进行投影，看看投影后的三个维度的方差分布，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">pca = PCA(n_components=3)</span><br><span class="line">pca.fit(X)</span><br><span class="line">print pca.explained_variance_ratio_</span><br><span class="line">print pca.explained_variance_</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<p>[ 0.98318212  0.00850037  0.00831751]</p>
<p>[ 3.78483785  0.03272285  0.03201892]</p>
<p>可以看出投影后三个特征维度的方差比例大约为98.3%：0.8%：0.8%。投影后第一个特征占了绝大多数的主成分比例。</p>
<p>现在我们来进行降维，从三维降到2维，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components=2)</span><br><span class="line">pca.fit(X)</span><br><span class="line">print pca.explained_variance_ratio_</span><br><span class="line">print pca.explained_variance_</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<p>[ 0.98318212  0.00850037]</p>
<p>[ 3.78483785  0.03272285]</p>
<p>这个结果其实可以预料，因为上面三个投影后的特征维度的方差分别为：[ 3.78483785  0.03272285  0.03201892]，投影到二维后选择的肯定是前两个特征，而抛弃第三个特征。</p>
<p>现在我们看看不直接指定降维的维度，而指定降维后的主成分方差和比例。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components=0.95)</span><br><span class="line">pca.fit(X)</span><br><span class="line">print pca.explained_variance_ratio_</span><br><span class="line">print pca.explained_variance_</span><br><span class="line">print pca.n_components_</span><br></pre></td></tr></table></figure></p>
<p>我们指定了主成分至少占95%，输出如下：</p>
<p>[ 0.98318212]</p>
<p>[ 3.78483785]</p>
<p>1</p>
<p>可见只有第一个投影特征被保留。这也很好理解，我们的第一个主成分占投影特征的方差比例高达98%。只选择这一个特征维度便可以满足95%的阈值。我们现在选择阈值99%看看，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components=0.99)</span><br><span class="line">pca.fit(X)</span><br><span class="line">print pca.explained_variance_ratio_</span><br><span class="line">print pca.explained_variance_</span><br><span class="line">print pca.n_components_</span><br></pre></td></tr></table></figure>
<p>此时的输出如下：</p>
<p>[ 0.98318212  0.00850037]</p>
<p>[ 3.78483785  0.03272285]</p>
<p>2</p>
<p>这个结果也很好理解，因为我们第一个主成分占了98.3%的方差比例，第二个主成分占了0.8%的方差比例，两者一起可以满足我们的阈值。</p>
<p>最后我们看看让MLE算法自己选择降维维度的效果，代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components=&apos;mle&apos;)</span><br><span class="line">pca.fit(X)</span><br><span class="line">print pca.explained_variance_ratio_</span><br><span class="line">print pca.explained_variance_</span><br><span class="line">print pca.n_components_</span><br></pre></td></tr></table></figure></p>
<p>输出结果如下：</p>
<p>[ 0.98318212]</p>
<p>[ 3.78483785]</p>
<p>1</p>
<p>可见由于我们的数据的第一个投影特征的方差占比高达98.3%，MLE算法只保留了我们的第一个特征。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://gaohangcs.com/2018/09/18/Java基础（一）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高航">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高航的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/18/Java基础（一）/" itemprop="url">Java基础（一）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-18T17:16:00+08:00">
                2018-09-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index">
                    <span itemprop="name">Java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="eclipse内容辅助键"><a href="#eclipse内容辅助键" class="headerlink" title="eclipse内容辅助键"></a>eclipse内容辅助键</h2><p>alt + /</p>
<pre><code>main，然后alt + /，回车

syso，然后alt + /，回车
</code></pre><hr>
<h2 id="eclipse内容快捷键"><a href="#eclipse内容快捷键" class="headerlink" title="eclipse内容快捷键"></a>eclipse内容快捷键</h2><p>注释：</p>
<pre><code>单行：选中内容，ctrl + /，再来一次就是取消注释
多行：选中内容，ctrl + shift + /，取消注释 ctrl + shift + \
格式化：
ctrl + shift + f    或  右键--source--format
</code></pre><h2 id="逻辑"><a href="#逻辑" class="headerlink" title="逻辑"></a>逻辑</h2><p>&amp;&amp;和&amp;结果一样</p>
<p>||和|结果一样</p>
<p>&amp;  左边是false，右边也要执行，返回false</p>
<p>&amp;&amp; 左边是false，右边则不执行，直接返回false</p>
<p>|  左边是true，右边也要执行，返回true</p>
<p>|| 左边是true，右边则不执行，直接返回true</p>
<h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><p>输入的步骤：</p>
<pre><code>A:导包

  import java.util.Scanner;

  类中的顺序：package &gt; import &gt; class

B:创建对象

  Scanner sc = new Scanner(System.in);

C:接收数据

  int i = sc.nextInt();
</code></pre><h3 id="关于导包"><a href="#关于导包" class="headerlink" title="关于导包"></a>关于导包</h3><pre><code>A:手动导包
  import java.util.Scanner;

B:鼠标点击红色叉叉，自动生成

C:快捷键(推荐)
  ctrl+shift+o
</code></pre><h2 id="Random-用于产生随机数"><a href="#Random-用于产生随机数" class="headerlink" title="Random:用于产生随机数"></a>Random:用于产生随机数</h2><p>###使用步骤：</p>
<pre><code>A:导包
  import java.util.Random;
B:创建对象
  Random r = new Random();
C:获取随机数
  int number = r.nextInt(10);
  获取数据的范围：[0,10) 包括0,不包括10
</code></pre><h3 id="Q：如何获取1-100之间的随机数呢"><a href="#Q：如何获取1-100之间的随机数呢" class="headerlink" title="Q：如何获取1-100之间的随机数呢?"></a>Q：如何获取1-100之间的随机数呢?</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//int i = r.nextInt(100); //[0,99]</span><br><span class="line">int i = r.nextInt(100) + 1;	//[1,100]</span><br><span class="line">System.out.println(&quot;i:&quot;+i);</span><br><span class="line"></span><br><span class="line">System.out.println():输出内容,并换行</span><br><span class="line">System.out.print():输出内容</span><br></pre></td></tr></table></figure>
<h2 id="方法重载"><a href="#方法重载" class="headerlink" title="方法重载"></a>方法重载</h2><p>###方法重载：在同一个类中，出现了方法名相同的情况。</p>
<p>###方法重载的特点：<br>    方法名相同，参数列表不同。与返回值无关。<br>    参数列表不同<br>    参数的个数不同<br>    参数对应的数据类型不同</p>
<p>###注意：<br>&emsp;&emsp;在调用方法的时候，java虚拟机会通过参数列表的不同来区分同名的方法。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://gaohangcs.com/2018/09/11/KNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高航">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高航的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/11/KNN/" itemprop="url">KNN学习笔记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-11T13:01:00+08:00">
                2018-09-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><ul>
<li><strong>是什么/原理</strong></li>
<li><strong>核心思想：“近朱者赤，近墨者黑”，由你的邻居来推断出你的类别</strong></li>
<li><strong>python实现</strong></li>
<li><strong>算法不足之处</strong></li>
</ul>
<hr>
<h2 id="是什么-原理"><a href="#是什么-原理" class="headerlink" title="是什么/原理"></a>是什么/原理</h2><ul>
<li>k近邻法（KNN）是一种基本分类与回归方法，是“懒惰学习”的代表，其算法的时间复杂度是O(n)，一般适用于样本数较少的数据集。其输出可以是多类。</li>
<li>k近邻法没有显式的学习过程，即没有训练阶段，数据集事先已有了分类和特征值，待收到新样本后直接进行处理。</li>
<li>相似度衡量方法：包括欧式距离（p=2）、曼哈顿距离（p=1）、夹角余弦。</li>
<li>简单应用中，一般使用欧氏距离，但对于文本分类来说，使用余弦来计算相似度就比欧式距离更合适。</li>
<li>K近邻法的三个基本要素是：k值的选择、距离度量、分类决策规则。</li>
</ul>
<h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>k近邻法中k值的选择会对k近邻法的结果产生重大影响。选取的k值若较小，就相当于用较小的领域中的训练实例进行预测，“学习”的近似误差会减小，只有与输入实例较近的训练实例才会对预测结果起作用，但缺点是“学习”的估计误差会增大，预测结果会对近邻的实例点非常敏感。反之，若选取的k值较大，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。K值的增大意味整体的模型变得简单（k值越小模型越复杂，k值较小可能产生过拟合的现象）。所以在应用中，k值一般取一个比较小的数值，通常采用交叉验证法来选取最优的k值。  </p>
<h3 id="Q：什么是近似误差和估计误差？"><a href="#Q：什么是近似误差和估计误差？" class="headerlink" title="Q：什么是近似误差和估计误差？"></a>Q：什么是近似误差和估计误差？</h3><p>近似误差可以理解为模型估计值与实际值之间的差距。<br>估计误差可以理解为模型的估计系数与实际系数之间的差距。<br>近似误差，更关注于“训练”。最小化近似误差，即为使估计值尽量接近真实值，这里的真实值指的是训练样本，模型本身并不是最接近真实分布。换一组样本可能就不近似了，这种训练样本表现好，测试样本表现不好的现象称为过拟合。<br>估计误差，更关注于“测试”、“泛化”。与近似误差相反，最小化估计误差，即为使估计系数尽量接近真实系数，可能此时对于训练样本得到的估计值不一定最接近真实值，但模型肯呢个更加接近真实分布。<br><img src="https://gss2.bdstatic.com/-fo3dSag_xI4khGkpoWK1HF6hhy/baike/w%3D268/sign=fc3731ea0ad162d985ee651a29dfa950/bf096b63f6246b60f20ccd5aebf81a4c510fa29a.jpg" alt="avatar"><br>如图（图片来自百度百科）<br>K值若较小，这里取内圈，红色三角占2/3，则绿色的未知物被判断为红色三角；<br>K值若较大，这里取外圈，蓝色方块占3/5，则绿色未知物被判断为蓝色方块。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *  <span class="comment"># 引入科学计算包</span></span><br><span class="line"><span class="keyword">import</span> operator  <span class="comment"># 经典python函数库。运算符模块。</span></span><br><span class="line"><span class="comment"># 创建数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    group = array([[<span class="number">1.0</span>, <span class="number">1.1</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">    labels = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 算法核心</span></span><br><span class="line"><span class="comment"># inX：用于分类的输入向量。即将对其进行分类。</span></span><br><span class="line"><span class="comment"># dataSet：训练样本集</span></span><br><span class="line"><span class="comment"># labels: 标签向量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classfy0</span><span class="params">(inX, dataSet, labels, k)</span>:</span></span><br><span class="line"><span class="comment"># 距离计算（这里用的欧氏距离）</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]  <span class="comment"># 得到数组的行数。即知道有几个训练数据</span></span><br><span class="line">    diffMat = tile(inX, (dataSetSize, <span class="number">1</span>)) - dataSet  <span class="comment"># tile:numpy中的函数。tile将原来的一个数组，扩充成了4个一样的数组。diffMat得到了目标与训练数值之间的差值。</span></span><br><span class="line">    sqDiffMat = diffMat ** <span class="number">2</span>  <span class="comment"># 各个元素分别平方</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>)  <span class="comment"># sum(axis=1)函数表示按行求和，一般默认</span></span><br></pre></td></tr></table></figure>
<p>###注释<br>axis=0即默认列求和<br>distances = sqDistances ** 0.5  # 开方，得到距离。<br>假如：（这里用的欧氏距离）<br>Newinput：[1,0,2]<br>Dataset:<br>[1,0,1]<br>[2,1,3]<br>[1,0,2]<br>计算过程即为：<br>1、求差<br>[1,0,1]   –    [1,0,2]  = [0,0,-1]<br>[2,1,3]   –    [1,0,2]  = [1,1,1]<br>[1,0,2]   –    [1,0,2]  = [0,0,-1]</p>
<p>2、对差值平方<br>[0,0,1]<br>[1,1,1]<br>[0,0,1]<br>3、将平方后的差值累加<br>1<br>3<br>1<br>4、将上一步骤的值求开方，即得距离<br>1<br>1.73<br>1<br>这就是以上的步骤</p>
<h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><pre><code class="python">sortedDistIndicies = distances.argsort()  <span class="comment"># 升序排列</span>
    <span class="comment"># 选择距离最小的k个点。</span>
    classCount = {}
    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span>
    <span class="comment"># 排序</span>
    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)     <span class="comment">#Python3.5中：iteritems变为items</span>
    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]

<span class="keyword">if</span> __name__== <span class="string">'__main__'</span>:
    dataSet, labels = createDataSet()
    input = array([<span class="number">1.1</span>, <span class="number">0.3</span>])
    K = <span class="number">3</span>
    output = classfy0(input, dataSet, labels, K)
print(<span class="string">"测试数据为:"</span>, input, <span class="string">"分类结果为："</span>, output)

</code></pre>
<h3 id="算法不足之处"><a href="#算法不足之处" class="headerlink" title="算法不足之处"></a>算法不足之处</h3><ol>
<li>样本不平衡容易导致结果错误；</li>
<li>计算量较大。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://gaohangcs.com/2018/09/08/使用CSDN-markdown编辑器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高航">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高航的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/08/使用CSDN-markdown编辑器/" itemprop="url">使用Markdown编辑器写博客</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-08T17:20:00+08:00">
                2018-09-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/杂谈/" itemprop="url" rel="index">
                    <span itemprop="name">杂谈</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li><strong>Markdown和扩展Markdown简洁的语法</strong></li>
<li><strong>代码块高亮</strong></li>
<li><strong>图片链接和图片上传</strong></li>
<li><strong><em>LaTex</em>数学公式</strong></li>
<li><strong>UML序列图和流程图</strong></li>
<li><strong>离线写博客</strong></li>
<li><strong>导入导出Markdown文件</strong></li>
<li><strong>丰富的快捷键</strong></li>
</ul>
<hr>
<h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><ul>
<li>加粗    <code>Ctrl + B</code> </li>
<li>斜体    <code>Ctrl + I</code> </li>
<li>引用    <code>Ctrl + Q</code></li>
<li>插入链接    <code>Ctrl + L</code></li>
<li>插入代码    <code>Ctrl + K</code></li>
<li>插入图片    <code>Ctrl + G</code></li>
<li>提升标题    <code>Ctrl + H</code></li>
<li>有序列表    <code>Ctrl + O</code></li>
<li>无序列表    <code>Ctrl + U</code></li>
<li>横线    <code>Ctrl + R</code></li>
<li>撤销    <code>Ctrl + Z</code></li>
<li>重做    <code>Ctrl + Y</code></li>
</ul>
<h2 id="Markdown及扩展"><a href="#Markdown及扩展" class="headerlink" title="Markdown及扩展"></a>Markdown及扩展</h2><blockquote>
<p>Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。    —— <a href="https://zh.wikipedia.org/wiki/Markdown" target="_blank"> [ 维基百科 ]</a></p>
</blockquote>
<p>使用简单的符号标识不同的标题，将某些文字标记为<strong>粗体</strong>或者<em>斜体</em>，创建一个<a href="http://www.csdn.net" target="_blank" rel="noopener">链接</a>等，详细语法参考帮助？。</p>
<p>本编辑器支持 <strong>Markdown Extra</strong> , 　扩展了很多好用的功能。具体请参考<a href="https://github.com/jmcmanus/pagedown-extra" title="Pagedown Extra" target="_blank" rel="noopener">Github</a>.  </p>
<h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p><strong>Markdown　Extra</strong>　表格语法：</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>价格</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computer</td>
<td>$1600</td>
</tr>
<tr>
<td>Phone</td>
<td>$12</td>
</tr>
<tr>
<td>Pipe</td>
<td>$1</td>
</tr>
</tbody>
</table>
<p>可以使用冒号来定义对齐方式：</p>
<table>
<thead>
<tr>
<th style="text-align:left">项目</th>
<th style="text-align:right">价格</th>
<th style="text-align:center">数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Computer</td>
<td style="text-align:right">1600 元</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:left">Phone</td>
<td style="text-align:right">12 元</td>
<td style="text-align:center">12</td>
</tr>
<tr>
<td style="text-align:left">Pipe</td>
<td style="text-align:right">1 元</td>
<td style="text-align:center">234</td>
</tr>
</tbody>
</table>
<p>###定义列表</p>
<p><strong>Markdown　Extra</strong>　定义列表语法：<br>项目１<br>项目２<br>:   定义 A<br>:   定义 B</p>
<p>项目３<br>:   定义 C</p>
<p>:   定义 D</p>
<pre><code>&gt; 定义D内容
</code></pre><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><p>代码块语法遵循标准markdown代码，例如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@requires_authorization</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">somefunc</span><span class="params">(param1=<span class="string">''</span>, param2=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''A docstring'''</span></span><br><span class="line">    <span class="keyword">if</span> param1 &gt; param2: <span class="comment"># interesting</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Greater'</span></span><br><span class="line">    <span class="keyword">return</span> (param2 - param1 + <span class="number">1</span>) <span class="keyword">or</span> <span class="keyword">None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SomeClass</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>message = <span class="string">'''interpreter</span></span><br><span class="line"><span class="string"><span class="meta">... </span>prompt'''</span></span><br></pre></td></tr></table></figure></p>
<p>###脚注<br>生成一个脚注[^footnote].<br>  [^footnote]: 这里是 <strong>脚注</strong> 的 <em>内容</em>.</p>
<h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><p>用 <code>[TOC]</code>来生成目录：</p>
<p>[TOC]</p>
<h3 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h3><p>使用MathJax渲染<em>LaTex</em> 数学公式，详见<a href="http://math.stackexchange.com/" target="_blank" rel="noopener">math.stackexchange.com</a>.</p>
<ul>
<li>行内公式，数学公式为：$\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$。</li>
<li>块级公式：</li>
</ul>
<p>$$    x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$</p>
<p>更多LaTex语法请参考 <a href="http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference" target="_blank" rel="noopener">这儿</a>.</p>
<h3 id="UML-图"><a href="#UML-图" class="headerlink" title="UML 图:"></a>UML 图:</h3><p>可以渲染序列图：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">张三-&gt;李四: 嘿，小四儿, 写博客了没?</span><br><span class="line">Note right of 李四: 李四愣了一下，说：</span><br><span class="line">李四--&gt;张三: 忙得吐血，哪有时间写。</span><br></pre></td></tr></table></figure>
<p>或者流程图：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: 开始</span><br><span class="line">e=&gt;end: 结束</span><br><span class="line">op=&gt;operation: 我的操作</span><br><span class="line">cond=&gt;condition: 确认？</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no)-&gt;op</span><br></pre></td></tr></table></figure>
<ul>
<li>关于 <strong>序列图</strong> 语法，参考 <a href="http://bramp.github.io/js-sequence-diagrams/" target="_blank" rel="noopener">这儿</a>,</li>
<li>关于 <strong>流程图</strong> 语法，参考 <a href="http://adrai.github.io/flowchart.js/" target="_blank" rel="noopener">这儿</a>.</li>
</ul>
<h2 id="离线写博客"><a href="#离线写博客" class="headerlink" title="离线写博客"></a>离线写博客</h2><p>即使用户在没有网络的情况下，也可以通过本编辑器离线写博客（直接在曾经使用过的浏览器中输入<a href="http://write.blog.csdn.net/mdeditor" target="_blank" rel="noopener">write.blog.csdn.net/mdeditor</a>即可。<strong>Markdown编辑器</strong>使用浏览器离线存储将内容保存在本地。</p>
<p>用户写博客的过程中，内容实时保存在浏览器缓存中，在用户关闭浏览器或者其它异常情况下，内容不会丢失。用户再次打开浏览器时，会显示上次用户正在编辑的没有发表的内容。</p>
<p>博客发表后，本地缓存将被删除。　</p>
<p>用户可以选择 <i class="icon-disk"></i> 把正在写的博客保存到服务器草稿箱，即使换浏览器或者清除缓存，内容也不会丢失。</p>
<blockquote>
<p><strong>注意：</strong>虽然浏览器存储大部分时候都比较可靠，但为了您的数据安全，在联网后，<strong>请务必及时发表或者保存到服务器草稿箱</strong>。</p>
</blockquote>
<p>##浏览器兼容</p>
<ol>
<li>目前，本编辑器对Chrome浏览器支持最为完整。建议大家使用较新版本的Chrome。</li>
<li>IE９以下不支持</li>
<li>IE９，１０，１１存在以下问题<ol>
<li>不支持离线功能</li>
<li>IE9不支持文件导入导出</li>
<li>IE10不支持拖拽文件导入</li>
</ol>
</li>
</ol>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="高航" />
            
              <p class="site-author-name" itemprop="name">高航</p>
              <p class="site-description motion-element" itemprop="description">开心就好</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archive">
              
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/HansGaoyeah" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:gaohangcs@whu.edu.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-globe"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-globe"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://qinjiangbo.com/" title="秦江波" target="_blank">秦江波</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://hegongshan.com/" title="贺巩山" target="_blank">贺巩山</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="www.hutianwei.park.bitcron.com" title="胡添维" target="_blank">胡添维</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://desire-zone.github.io" title="王志文" target="_blank">王志文</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">true</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user">访客数</i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye">阅读数</i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
